#!/usr/bin/env python3
"""
Chainlink CRE Workflow Framework
@requirement: REQ-CRE-001 - Core CRE Workflow Framework
@component: Chainlink Runtime Environment Integration
@integration: ETAC System strategic platform and MetaMask infrastructure
"""

import json
import asyncio
import time
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, asdict
from pathlib import Path
import sys
import os

# Add ETAC system to path
sys.path.insert(0, '/home/craigmbrown/Project/ETAC-System')

# Import ETAC core modules
try:
    from strategic_platform.core.security_infrastructure_logger import SecurityInfrastructureLogger
    from strategic_platform.core.base_level_properties import BaseLevelPropertyManager, PropertyCategory
    from strategic_platform.core.agent_core_directives import (
        UniversalAgentDirective, AgentProperty, create_etac_agent, improve_agent_for_requirement
    )
    from strategic_platform.utils.enhanced_exception_handler import (
        enhanced_exception_handler, ETACException, ETACAPIError
    )
    print("‚úÖ Successfully imported ETAC core modules")
    
    # Import x402 Payment Handler
    from x402_payment_handler import (
        X402PaymentHandler, X402PaymentRequest, X402PaymentChannel, PaymentStatus
    )
    print("‚úÖ Successfully imported x402 Payment Handler")
except ImportError as e:
    print(f"‚ö†Ô∏è Could not import ETAC modules: {e}")
    # Fallback imports
    def enhanced_exception_handler(*args, **kwargs):
        def decorator(func):
            def wrapper(*func_args, **func_kwargs):
                try:
                    return func(*func_args, **func_kwargs)
                except Exception as e:
                    print(f"‚ùå Exception in {func.__name__}: {str(e)}")
                    import traceback
                    print(f"üîç Full traceback: {traceback.format_exc()}")
                    raise
            return wrapper
        return decorator
    
    class SecurityInfrastructureLogger:
        def log_security_event(self, component, event, data):
            print(f"üîê Security Event - {component}: {event} - {data}")
    
    class BaseLevelPropertyManager:
        def update_property_score(self, prop, delta, reason):
            print(f"üìä Property Update: {prop} {delta:+.2f} - {reason}")
    
    # x402 Payment Handler fallback classes
    class X402PaymentHandler:
        def __init__(self, *args, **kwargs):
            print("‚ö†Ô∏è Using fallback x402 Payment Handler")
    
    class X402PaymentRequest:
        pass
    
    class PaymentStatus:
        COMPLETED = "completed"
    
    class ETACException(Exception):
        pass
    
    class ETACAPIError(Exception):
        pass

@dataclass
class CREWorkflowDefinition:
    """
    @requirement: REQ-CRE-001 - CRE Workflow Definition
    Defines a Chainlink CRE workflow with AI capabilities and monetization
    """
    workflow_id: str
    name: str
    description: str
    category: str  # prediction, defi, analytics, automation
    version: str
    ai_models_required: List[str]
    chainlink_feeds_required: List[str]
    input_schema: Dict[str, Any]
    output_schema: Dict[str, Any]
    pricing_model: str  # per_call, subscription, performance_based
    base_price_link: float
    estimated_gas_cost: int
    execution_timeout_ms: int
    properties_enhanced: Dict[str, float]
    created_at: datetime = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()

@dataclass
class CREWorkflowExecution:
    """
    @requirement: REQ-CRE-002 - CRE Workflow Execution Tracking
    Track individual workflow executions with performance metrics
    """
    execution_id: str
    workflow_id: str
    input_data: Dict[str, Any]
    output_data: Optional[Dict[str, Any]] = None
    status: str = "pending"  # pending, running, completed, failed
    start_time: datetime = None
    end_time: Optional[datetime] = None
    gas_used: Optional[int] = None
    payment_amount_link: Optional[float] = None
    error_message: Optional[str] = None
    confidence_score: Optional[float] = None
    
    def __post_init__(self):
        if self.start_time is None:
            self.start_time = datetime.now()
    
    @property
    def execution_time_ms(self) -> Optional[int]:
        """Calculate execution time in milliseconds"""
        if self.end_time and self.start_time:
            return int((self.end_time - self.start_time).total_seconds() * 1000)
        return None
    
    @property
    def is_successful(self) -> bool:
        """Check if execution was successful"""
        return self.status == "completed" and self.error_message is None

@dataclass
class CREPaymentChannel:
    """
    @requirement: REQ-CRE-003 - CRE Payment Channel Management
    Manage x402 payment channels for CRE workflow payments
    """
    channel_id: str
    workflow_id: str
    payer_address: str
    receiver_address: str
    token_address: str  # LINK token
    channel_balance: float
    payment_count: int = 0
    total_payments: float = 0.0
    last_payment: Optional[datetime] = None
    status: str = "active"  # active, suspended, closed

class ChainlinkCREWorkflowFramework:
    """
    @requirement: REQ-CRE-004 - Chainlink CRE Workflow Framework
    Core framework for creating, managing, and executing Chainlink CRE workflows
    """
    
    def __init__(self, project_root: str = "/home/craigmbrown/Project/chainlink-prediction-markets-mcp"):
        self.project_root = Path(project_root)
        self.logger = SecurityInfrastructureLogger()
        self.blp_manager = BaseLevelPropertyManager()
        
        # Initialize ETAC agent
        self.agent = create_etac_agent("ChainlinkCREFramework", "cre_workflow")
        
        # Initialize x402 Payment Handler
        try:
            self.payment_handler = X402PaymentHandler(project_root)
            print("‚úÖ x402 Payment Handler integrated")
        except Exception as e:
            print(f"‚ö†Ô∏è Could not initialize x402 Payment Handler: {e}")
            self.payment_handler = None
        
        # Workflow management
        self.registered_workflows: Dict[str, CREWorkflowDefinition] = {}
        self.execution_history: Dict[str, CREWorkflowExecution] = {}
        self.payment_channels: Dict[str, CREPaymentChannel] = {}  # Legacy - migrating to x402
        
        # Framework state
        self.framework_id = hashlib.md5(f"cre_framework_{datetime.now().isoformat()}".encode()).hexdigest()[:16]
        self.initialized_at = datetime.now()
        
        # Storage
        self.storage_dir = self.project_root / "chainlink_cre" / "storage"
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        # Load existing data
        self._load_framework_data()
        
        # Initialize with design specifications if empty
        if not self.registered_workflows:
            self._load_design_specifications()
        
        self.logger.log_security_event(
            "chainlink_cre_framework",
            "INITIALIZED",
            {
                "framework_id": self.framework_id,
                "workflows_loaded": len(self.registered_workflows),
                "agent_id": self.agent.agent_id
            }
        )
        print(f"‚úÖ Chainlink CRE Workflow Framework initialized - {len(self.registered_workflows)} workflows loaded")

    @enhanced_exception_handler(retry_attempts=2, component_name="CREWorkflowFramework")
    async def register_workflow(self, workflow_definition: CREWorkflowDefinition) -> bool:
        """
        @requirement: REQ-CRE-005 - Register CRE Workflow
        Register a new CRE workflow with the framework
        """
        print(f"üìã Registering CRE workflow: {workflow_definition.name}")
        
        try:
            # Validate workflow definition
            if not workflow_definition.workflow_id:
                raise ETACException("Workflow ID is required", "WorkflowRegistration")
            
            if workflow_definition.workflow_id in self.registered_workflows:
                print(f"‚ö†Ô∏è Workflow {workflow_definition.workflow_id} already exists - updating")
            
            # Store workflow
            self.registered_workflows[workflow_definition.workflow_id] = workflow_definition
            
            # Update agent properties based on workflow capabilities
            property_improvements = workflow_definition.properties_enhanced
            for prop_name, delta in property_improvements.items():
                if hasattr(AgentProperty, prop_name.upper()):
                    agent_property = getattr(AgentProperty, prop_name.upper())
                    self.agent.update_property(agent_property, delta, f"workflow_{workflow_definition.workflow_id}")
            
            # Save framework data
            self._save_framework_data()
            
            # Record successful operation
            self.agent.record_operation(True, "workflow_registration")
            
            self.logger.log_security_event(
                "workflow_registration",
                "COMPLETED",
                {
                    "workflow_id": workflow_definition.workflow_id,
                    "category": workflow_definition.category,
                    "ai_models": workflow_definition.ai_models_required,
                    "pricing_model": workflow_definition.pricing_model
                }
            )
            
            print(f"‚úÖ Workflow registered: {workflow_definition.workflow_id}")
            return True
            
        except Exception as e:
            self.agent.record_operation(False, "workflow_registration")
            self.logger.log_security_event(
                "workflow_registration",
                "FAILED",
                {"workflow_id": workflow_definition.workflow_id, "error": str(e)}
            )
            raise ETACAPIError(f"Failed to register workflow: {str(e)}", "WorkflowRegistration")

    @enhanced_exception_handler(retry_attempts=3, component_name="CREWorkflowFramework")
    async def execute_workflow(self, workflow_id: str, input_data: Dict[str, Any], payment_channel_id: Optional[str] = None) -> CREWorkflowExecution:
        """
        @requirement: REQ-CRE-006 - Execute CRE Workflow
        Execute a registered CRE workflow with input data
        """
        
        # Validate workflow exists
        if workflow_id not in self.registered_workflows:
            raise ETACException(f"Workflow {workflow_id} not found", "WorkflowExecution")
        
        workflow = self.registered_workflows[workflow_id]
        
        # Create execution tracking
        execution_id = hashlib.md5(f"{workflow_id}_{datetime.now().isoformat()}_{json.dumps(input_data)}".encode()).hexdigest()[:16]
        execution = CREWorkflowExecution(
            execution_id=execution_id,
            workflow_id=workflow_id,
            input_data=input_data,
            status="running"
        )
        
        print(f"üöÄ Executing workflow: {workflow.name} (ID: {execution_id})")
        
        try:
            # Validate input data against schema
            if not self._validate_input_data(input_data, workflow.input_schema):
                raise ETACException("Input data validation failed", "WorkflowExecution")
            
            # Process payment if required
            if payment_channel_id and workflow.base_price_link > 0:
                payment_success = await self._process_workflow_payment(
                    payment_channel_id, workflow.base_price_link, execution_id
                )
                if not payment_success:
                    raise ETACException("Payment processing failed", "WorkflowExecution")
                execution.payment_amount_link = workflow.base_price_link
            
            # Execute workflow based on category
            output_data = await self._execute_workflow_logic(workflow, input_data)
            
            # Complete execution
            execution.status = "completed"
            execution.end_time = datetime.now()
            execution.output_data = output_data
            execution.gas_used = workflow.estimated_gas_cost  # Mock gas usage
            
            # Store execution
            self.execution_history[execution_id] = execution
            
            # Update agent properties for successful execution
            self.agent.update_property(AgentProperty.AUTONOMY, 0.002, f"workflow_execution_{workflow_id}")
            self.agent.update_property(AgentProperty.SELF_IMPROVEMENT, 0.001, "workflow_learning")
            
            # Record successful operation
            self.agent.record_operation(True, "workflow_execution")
            
            self.logger.log_security_event(
                "workflow_execution",
                "COMPLETED",
                {
                    "execution_id": execution_id,
                    "workflow_id": workflow_id,
                    "execution_time_ms": execution.execution_time_ms,
                    "payment_amount": execution.payment_amount_link
                }
            )
            
            print(f"‚úÖ Workflow execution completed: {execution_id} ({execution.execution_time_ms}ms)")
            self._save_framework_data()
            return execution
            
        except Exception as e:
            execution.status = "failed"
            execution.end_time = datetime.now()
            execution.error_message = str(e)
            
            # Store failed execution for analysis
            self.execution_history[execution_id] = execution
            
            self.agent.record_operation(False, "workflow_execution")
            
            self.logger.log_security_event(
                "workflow_execution",
                "FAILED",
                {
                    "execution_id": execution_id,
                    "workflow_id": workflow_id,
                    "error": str(e)
                }
            )
            
            print(f"‚ùå Workflow execution failed: {execution_id} - {str(e)}")
            self._save_framework_data()
            raise

    async def _execute_workflow_logic(self, workflow: CREWorkflowDefinition, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        @requirement: REQ-CRE-007 - Execute Workflow Logic
        Execute the actual workflow logic based on category and AI models
        """
        
        print(f"ü§ñ Executing {workflow.category} workflow: {workflow.name}")
        
        # Simulate AI model processing time
        await asyncio.sleep(workflow.execution_timeout_ms / 1000.0)
        
        if workflow.category == "prediction":
            return await self._execute_prediction_workflow(workflow, input_data)
        elif workflow.category == "defi":
            return await self._execute_defi_workflow(workflow, input_data)
        elif workflow.category == "analytics":
            return await self._execute_analytics_workflow(workflow, input_data)
        else:
            return await self._execute_generic_workflow(workflow, input_data)

    async def _execute_prediction_workflow(self, workflow: CREWorkflowDefinition, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Execute prediction-based workflows"""
        
        symbol = input_data.get("symbol", "BTC")
        timeframe = input_data.get("timeframe", "4h")
        
        # Mock AI prediction logic
        import random
        prediction_confidence = random.uniform(0.6, 0.95)
        price_change_prediction = random.uniform(-0.15, 0.15)  # -15% to +15%
        sentiment_score = random.uniform(-0.5, 0.5)
        
        return {
            "price_prediction": price_change_prediction,
            "confidence": prediction_confidence,
            "sentiment_score": sentiment_score,
            "key_factors": [
                "market_momentum",
                "social_sentiment",
                f"technical_analysis_{timeframe}"
            ],
            "timestamp": datetime.now().isoformat(),
            "model_used": workflow.ai_models_required[0] if workflow.ai_models_required else "gpt-4",
            "symbol_analyzed": symbol,
            "timeframe": timeframe
        }

    async def _execute_defi_workflow(self, workflow: CREWorkflowDefinition, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Execute DeFi optimization workflows"""
        
        wallet_address = input_data.get("wallet_address", "0x...")
        risk_tolerance = input_data.get("risk_tolerance", "medium")
        
        # Mock DeFi optimization logic
        import random
        protocols = ["Aave", "Compound", "Uniswap", "Curve", "Yearn"]
        strategies = []
        
        for i in range(3):
            strategies.append({
                "protocol": random.choice(protocols),
                "apy": random.uniform(0.02, 0.25),
                "risk_score": random.uniform(0.1, 0.8),
                "allocation_percentage": random.uniform(0.1, 0.5)
            })
        
        total_expected_apy = sum(s["apy"] * s["allocation_percentage"] for s in strategies)
        
        return {
            "optimal_strategies": strategies,
            "total_expected_apy": total_expected_apy,
            "risk_assessment": {
                "overall_risk": random.uniform(0.2, 0.7),
                "diversification_score": random.uniform(0.6, 0.9),
                "liquidity_risk": random.uniform(0.1, 0.4)
            },
            "wallet_analyzed": wallet_address,
            "risk_tolerance": risk_tolerance,
            "timestamp": datetime.now().isoformat()
        }

    async def _execute_analytics_workflow(self, workflow: CREWorkflowDefinition, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Execute analytics workflows"""
        
        return {
            "analysis_result": "analytics_completed",
            "metrics": {
                "data_points_processed": random.randint(1000, 10000),
                "patterns_identified": random.randint(5, 25),
                "confidence_score": random.uniform(0.7, 0.95)
            },
            "timestamp": datetime.now().isoformat()
        }

    async def _execute_generic_workflow(self, workflow: CREWorkflowDefinition, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Execute generic workflows"""
        
        return {
            "workflow_result": "completed",
            "processed_data": input_data,
            "execution_metadata": {
                "workflow_id": workflow.workflow_id,
                "execution_time": datetime.now().isoformat(),
                "ai_models_used": workflow.ai_models_required
            }
        }

    def _validate_input_data(self, input_data: Dict[str, Any], schema: Dict[str, Any]) -> bool:
        """
        @requirement: REQ-CRE-008 - Validate Input Data
        Validate input data against workflow schema
        """
        
        # Basic validation - check required fields
        for field_name, field_spec in schema.items():
            if field_spec.get("required", False) and field_name not in input_data:
                print(f"‚ùå Required field missing: {field_name}")
                return False
        
        print(f"‚úÖ Input data validation passed")
        return True

    async def _process_workflow_payment(self, channel_id: str, amount: float, execution_id: str) -> bool:
        """
        @requirement: REQ-CRE-009 - Process Workflow Payment
        Process x402 payment for workflow execution using integrated payment handler
        """
        
        print(f"üí≥ Processing payment: {amount} LINK via x402 handler")
        
        if not self.payment_handler:
            print(f"‚ö†Ô∏è x402 Payment Handler not available, using fallback")
            return await self._fallback_payment_processing(channel_id, amount, execution_id)
        
        try:
            # Create x402 payment request
            from decimal import Decimal
            payment_request = X402PaymentRequest(
                request_id=f"workflow_{execution_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                workflow_id=execution_id.split('_')[0] if '_' in execution_id else "unknown",
                payer_address="0x742D35Cc6678d5c6e7b3c3F4F6e52738a8c1D5d3",  # Default test address
                receiver_address="0x1234567890123456789012345678901234567890",  # Default receiver
                amount_link=Decimal(str(amount)),
                payment_type="per_call",
                metadata={"execution_id": execution_id, "workflow_payment": True}
            )
            
            # Process payment through x402 handler
            transaction = await self.payment_handler.process_payment(payment_request, channel_id)
            
            if transaction.status == PaymentStatus.COMPLETED:
                print(f"‚úÖ x402 payment completed: {transaction.tx_id} ({amount} LINK)")
                return True
            else:
                print(f"‚ùå x402 payment failed: {transaction.error_message}")
                return False
                
        except Exception as e:
            print(f"‚ùå x402 payment error: {str(e)}")
            return False
    
    async def _fallback_payment_processing(self, channel_id: str, amount: float, execution_id: str) -> bool:
        """Fallback payment processing for when x402 handler is unavailable"""
        
        # Simulate payment delay
        await asyncio.sleep(0.5)
        
        # Update legacy payment channel if exists
        if channel_id in self.payment_channels:
            channel = self.payment_channels[channel_id]
            if channel.channel_balance >= amount:
                channel.channel_balance -= amount
                channel.payment_count += 1
                channel.total_payments += amount
                channel.last_payment = datetime.now()
                
                print(f"‚úÖ Fallback payment processed: {amount} LINK (remaining balance: {channel.channel_balance})")
                return True
            else:
                print(f"‚ùå Insufficient channel balance: {channel.channel_balance} < {amount}")
                return False
        
        # For new channels, assume payment succeeds
        print(f"‚úÖ Fallback payment processed via new channel: {amount} LINK")
        return True

    def get_workflow_analytics(self) -> Dict[str, Any]:
        """
        @requirement: REQ-CRE-010 - Get Workflow Analytics
        Generate comprehensive analytics for all workflows
        """
        
        analytics = {
            "framework_info": {
                "framework_id": self.framework_id,
                "initialized_at": self.initialized_at.isoformat(),
                "total_workflows": len(self.registered_workflows),
                "total_executions": len(self.execution_history)
            },
            "workflow_statistics": {},
            "execution_metrics": {
                "total_executions": len(self.execution_history),
                "successful_executions": len([e for e in self.execution_history.values() if e.is_successful]),
                "failed_executions": len([e for e in self.execution_history.values() if not e.is_successful]),
                "average_execution_time_ms": 0,
                "total_gas_used": 0,
                "total_payments_link": 0
            },
            "agent_performance": self.agent.get_agent_summary(),
            "generated_at": datetime.now().isoformat()
        }
        
        # Calculate execution metrics
        successful_executions = [e for e in self.execution_history.values() if e.is_successful]
        
        if successful_executions:
            execution_times = [e.execution_time_ms for e in successful_executions if e.execution_time_ms]
            if execution_times:
                analytics["execution_metrics"]["average_execution_time_ms"] = sum(execution_times) / len(execution_times)
            
            total_gas = sum(e.gas_used or 0 for e in successful_executions)
            analytics["execution_metrics"]["total_gas_used"] = total_gas
            
            total_payments = sum(e.payment_amount_link or 0 for e in successful_executions)
            analytics["execution_metrics"]["total_payments_link"] = total_payments
        
        # Workflow-specific statistics
        for workflow_id, workflow in self.registered_workflows.items():
            workflow_executions = [e for e in self.execution_history.values() if e.workflow_id == workflow_id]
            
            analytics["workflow_statistics"][workflow_id] = {
                "name": workflow.name,
                "category": workflow.category,
                "total_executions": len(workflow_executions),
                "successful_executions": len([e for e in workflow_executions if e.is_successful]),
                "success_rate": (
                    len([e for e in workflow_executions if e.is_successful]) / len(workflow_executions)
                    if workflow_executions else 0
                ),
                "total_revenue_link": sum(e.payment_amount_link or 0 for e in workflow_executions if e.is_successful)
            }
        
        # Success rate calculation
        if analytics["execution_metrics"]["total_executions"] > 0:
            analytics["execution_metrics"]["success_rate"] = (
                analytics["execution_metrics"]["successful_executions"] / 
                analytics["execution_metrics"]["total_executions"]
            )
        
        return analytics

    def _load_design_specifications(self):
        """
        @requirement: REQ-CRE-011 - Load Design Specifications
        Load workflow specifications from design agent output
        """
        
        design_output_dir = self.project_root / "design_outputs" / "specifications"
        workflow_specs_file = design_output_dir / "workflow_specs.json"
        
        if not workflow_specs_file.exists():
            print(f"‚ö†Ô∏è Design specifications not found at {workflow_specs_file}")
            return
        
        try:
            with open(workflow_specs_file, 'r') as f:
                workflow_specs = json.load(f)
            
            for workflow_id, spec_data in workflow_specs.items():
                # Convert to CREWorkflowDefinition
                workflow = CREWorkflowDefinition(
                    workflow_id=workflow_id,
                    name=spec_data["name"],
                    description=spec_data["description"],
                    category=spec_data["category"],
                    version="1.0",
                    ai_models_required=spec_data["ai_models_required"],
                    chainlink_feeds_required=spec_data["chainlink_feeds_required"],
                    input_schema=spec_data["input_schema"],
                    output_schema=spec_data["output_schema"],
                    pricing_model=spec_data["pricing_model"],
                    base_price_link=spec_data["base_price_link"],
                    estimated_gas_cost=spec_data["estimated_gas_cost"],
                    execution_timeout_ms=spec_data["expected_execution_time_ms"],
                    properties_enhanced=spec_data["properties_enhanced"],
                    created_at=datetime.fromisoformat(spec_data["created_at"])
                )
                
                self.registered_workflows[workflow_id] = workflow
            
            print(f"‚úÖ Loaded {len(workflow_specs)} workflows from design specifications")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to load design specifications: {str(e)}")

    def _save_framework_data(self):
        """Save framework data to persistent storage"""
        
        framework_data = {
            "framework_info": {
                "framework_id": self.framework_id,
                "initialized_at": self.initialized_at.isoformat(),
                "agent_id": self.agent.agent_id
            },
            "workflows": {
                workflow_id: asdict(workflow) for workflow_id, workflow in self.registered_workflows.items()
            },
            "executions": {
                exec_id: asdict(execution) for exec_id, execution in list(self.execution_history.items())[-100:]  # Last 100
            },
            "payment_channels": {
                channel_id: asdict(channel) for channel_id, channel in self.payment_channels.items()
            },
            "saved_at": datetime.now().isoformat()
        }
        
        # Convert datetime objects to strings
        for workflow_data in framework_data["workflows"].values():
            if isinstance(workflow_data.get("created_at"), datetime):
                workflow_data["created_at"] = workflow_data["created_at"].isoformat()
        
        for exec_data in framework_data["executions"].values():
            for time_field in ["start_time", "end_time"]:
                if isinstance(exec_data.get(time_field), datetime):
                    exec_data[time_field] = exec_data[time_field].isoformat()
        
        for channel_data in framework_data["payment_channels"].values():
            if isinstance(channel_data.get("last_payment"), datetime):
                channel_data["last_payment"] = channel_data["last_payment"].isoformat()
        
        storage_file = self.storage_dir / f"cre_framework_{self.framework_id}.json"
        
        try:
            with open(storage_file, 'w') as f:
                json.dump(framework_data, f, indent=2, default=str)
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to save framework data: {str(e)}")

    def _load_framework_data(self):
        """Load framework data from persistent storage"""
        
        # Find the most recent framework data file
        framework_files = list(self.storage_dir.glob("cre_framework_*.json"))
        if not framework_files:
            return
        
        latest_file = max(framework_files, key=lambda f: f.stat().st_mtime)
        
        try:
            with open(latest_file, 'r') as f:
                data = json.load(f)
            
            # Load workflows
            for workflow_id, workflow_data in data.get("workflows", {}).items():
                if isinstance(workflow_data.get("created_at"), str):
                    workflow_data["created_at"] = datetime.fromisoformat(workflow_data["created_at"])
                
                workflow = CREWorkflowDefinition(**workflow_data)
                self.registered_workflows[workflow_id] = workflow
            
            # Load executions
            for exec_id, exec_data in data.get("executions", {}).items():
                for time_field in ["start_time", "end_time"]:
                    if isinstance(exec_data.get(time_field), str):
                        exec_data[time_field] = datetime.fromisoformat(exec_data[time_field])
                
                execution = CREWorkflowExecution(**exec_data)
                self.execution_history[exec_id] = execution
            
            # Load payment channels
            for channel_id, channel_data in data.get("payment_channels", {}).items():
                if isinstance(channel_data.get("last_payment"), str):
                    channel_data["last_payment"] = datetime.fromisoformat(channel_data["last_payment"])
                
                channel = CREPaymentChannel(**channel_data)
                self.payment_channels[channel_id] = channel
            
            print(f"‚úÖ Loaded framework data from {latest_file}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to load framework data: {str(e)}")


async def main():
    """
    @requirement: REQ-CRE-012 - Main CRE Framework Testing
    Test the Chainlink CRE Workflow Framework
    """
    print("\nüöÄ Testing Chainlink CRE Workflow Framework")
    print("=" * 80)
    
    try:
        # Initialize framework
        framework = ChainlinkCREWorkflowFramework()
        
        # Test workflow execution
        if framework.registered_workflows:
            workflow_id = list(framework.registered_workflows.keys())[0]
            print(f"\nüß™ Testing workflow: {workflow_id}")
            
            # Test input data based on workflow type
            test_input = {"symbol": "BTC", "timeframe": "4h", "analysis_depth": "basic"}
            
            # Execute workflow
            execution = await framework.execute_workflow(workflow_id, test_input)
            
            print(f"\nüìä Execution Results:")
            print(f"   ID: {execution.execution_id}")
            print(f"   Status: {execution.status}")
            print(f"   Time: {execution.execution_time_ms}ms")
            print(f"   Output: {json.dumps(execution.output_data, indent=2)[:200]}...")
        
        # Get analytics
        analytics = framework.get_workflow_analytics()
        
        print(f"\nüìà Framework Analytics:")
        print(f"   Total Workflows: {analytics['framework_info']['total_workflows']}")
        print(f"   Total Executions: {analytics['execution_metrics']['total_executions']}")
        print(f"   Success Rate: {analytics['execution_metrics'].get('success_rate', 0):.1%}")
        print(f"   Agent Performance: {analytics['agent_performance']['performance']['average_property_score']:.3f}")
        
        print(f"\n‚úÖ CRE Workflow Framework operational and ready!")
        return analytics
        
    except Exception as e:
        print(f"‚ùå CRE Framework test failed: {str(e)}")
        import traceback

# Claude Advanced Tools Integration
try:
    from claude_advanced_tools import ToolRegistry, ToolSearchEngine, PatternLearner
    ADVANCED_TOOLS_ENABLED = True
except ImportError:
    ADVANCED_TOOLS_ENABLED = False

        print(f"üîç Full traceback: {traceback.format_exc()}")
        return {"error": str(e)}


if __name__ == "__main__":
    # Run the CRE Workflow Framework test
    result = asyncio.run(main())
    
    # Output JSON result for integration
    print(f"\nüì§ Framework Test Result:")
    print(json.dumps(result, indent=2, default=str))